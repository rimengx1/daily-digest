#!/usr/bin/env python3
"""
Twitter Monitor - è‡ªåŠ¨æŠ“å–Twitterå¹¶æ›´æ–°ç½‘ç«™
ä¿ç•™åŸæœ‰æ•°æ®ï¼Œåªæ›´æ–°thoughtsï¼ˆæ¨ç‰¹ç›‘æ§ï¼‰
"""
import json
import os
import re
import sys
from datetime import datetime

print("=" * 60)
print("ğŸš€ Twitter Monitor å¯åŠ¨")
print(f"â° {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print("=" * 60)

# åŠ è½½ç°æœ‰æ•°æ®
def load_existing_data():
    """è¯»å–ç°æœ‰çš„app.jsï¼Œä¿ç•™æ‰€æœ‰æ•°æ®"""
    import os
    
    # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•
    script_dir = os.path.dirname(os.path.abspath(__file__))
    
    # å°è¯•å¤šä¸ªè·¯å¾„
    paths = [
        os.path.join(script_dir, 'daily-digest', 'app.js'),
        os.path.join(script_dir, '..', 'daily-digest', 'app.js'),
        'daily-digest/app.js',
        './daily-digest/app.js',
        '../daily-digest/app.js',
        os.path.join(os.getcwd(), 'daily-digest', 'app.js')
    ]
    
    print(f"ğŸ“‚ å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
    print(f"ğŸ“‚ è„šæœ¬ç›®å½•: {script_dir}")
    print(f"ğŸ” æœç´¢ app.js...")
    
    for path in paths:
        full_path = os.path.abspath(path)
        print(f"   æ£€æŸ¥: {full_path}")
        if os.path.exists(full_path):
            try:
                with open(full_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    # æå–JSON
                    match = re.search(r'const dailyContent = ({.*?});\s*$', content, re.DOTALL)
                    if match:
                        data = json.loads(match.group(1))
                        print(f"âœ… è¯»å–æˆåŠŸ: {full_path}")
                        print(f"   - RSS: {len(data.get('rss', []))} æ¡")
                        print(f"   - AI: {len(data.get('ai', []))} æ¡")
                        print(f"   - æ¨è: {len(data.get('rec', []))} æ¡")
                        return data, full_path
            except Exception as e:
                print(f"   âš ï¸ è¯»å–å¤±è´¥: {e}")
                continue
    
    print("âŒ æ‰¾ä¸åˆ°æœ‰æ•ˆçš„ app.js æ–‡ä»¶")
    return None, None

# å°è¯•æŠ“å–Twitterï¼ˆç®€åŒ–ç‰ˆï¼Œä¸ä¾èµ–feedparserï¼‰
def fetch_tweets_simple():
    """ç®€åŒ–ç‰ˆæŠ“å–ï¼Œä½¿ç”¨æµ‹è¯•æ•°æ®æˆ–API"""
    print("\nğŸ“¡ å°è¯•æŠ“å–Twitter...")
    
    # å…ˆå°è¯•ä½¿ç”¨requestsç›´æ¥æŠ“å–Nitter
    try:
        import requests
        from xml.etree import ElementTree as ET
        
        accounts = ["sama", "karpathy", "ylecun", "DrJimFan", "jeremyphoward"]
        all_tweets = []
        
        for username in accounts[:3]:  # å…ˆæŠ“3ä¸ªè´¦å·æµ‹è¯•
            try:
                url = f"https://nitter.net/{username}/rss"
                resp = requests.get(url, timeout=10, headers={
                    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"
                })
                if resp.status_code == 200:
                    # ç®€å•è§£æRSS
                    root = ET.fromstring(resp.content)
                    items = root.findall('.//item')[:2]  # æ¯ä¸ªè´¦å·å–2æ¡
                    for item in items:
                        title = item.find('title')
                        link = item.find('link')
                        if title is not None:
                            all_tweets.append({
                                "author": f"@{username}",
                                "content": title.text[:200],
                                "link": link.text if link is not None else "#",
                                "time": datetime.now().strftime("%H:%M")
                            })
                    print(f"  âœ… @{username}: {len(items)}æ¡")
            except Exception as e:
                print(f"  âŒ @{username}: {e}")
        
        if all_tweets:
            return all_tweets
            
    except Exception as e:
        print(f"âš ï¸ æŠ“å–å¤±è´¥: {e}")
    
    # å¦‚æœæŠ“å–å¤±è´¥ï¼Œè¿”å›æµ‹è¯•æ•°æ®
    print("âš ï¸ ä½¿ç”¨æµ‹è¯•æ•°æ®")
    return [
        {"author": "@sama", "content": "AI is changing everything. We're just getting started.", "link": "https://x.com/sama", "time": "åˆšåˆš"},
        {"author": "@karpathy", "content": "New neural architecture shows promising results.", "link": "https://x.com/karpathy", "time": "5åˆ†é’Ÿå‰"},
        {"author": "@ylecun", "content": "Open source AI is the future.", "link": "https://x.com/ylecun", "time": "10åˆ†é’Ÿå‰"},
    ]

# AIè¯„åˆ†ï¼ˆå¯é€‰ï¼‰
def ai_score(tweets):
    """å¦‚æœæœ‰DeepSeek API Keyï¼Œè¿›è¡ŒAIè¯„åˆ†"""
    api_key = os.getenv('DEEPSEEK_API_KEY')
    if not api_key:
        print("âš ï¸ æ— DeepSeek API Keyï¼Œè·³è¿‡AIè¯„åˆ†")
        for t in tweets:
            t['score'] = 50
            t['summary'] = t['content'][:80] + "..." if len(t['content']) > 80 else t['content']
            t['category'] = "å…¶ä»–"
        return tweets
    
    print("\nğŸ¤– DeepSeek AIè¯„åˆ†ä¸­...")
    try:
        import requests
        for tweet in tweets:
            try:
                prompt = f"""åˆ†ææ¨æ–‡ï¼Œè¿”å›JSONï¼š{{"score":0-100,"summary":"20å­—æ‘˜è¦","category":"æŠ€æœ¯/äº§å“/è§‚ç‚¹/å…¶ä»–"}}
æ¨æ–‡ï¼š{tweet['content'][:500]}
åªè¿”å›JSONã€‚"""
                
                resp = requests.post(
                    "https://api.deepseek.com/v1/chat/completions",
                    headers={"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"},
                    json={"model": "deepseek-chat", "messages": [{"role": "user", "content": prompt}], "temperature": 0.3},
                    timeout=30
                )
                result = resp.json()['choices'][0]['message']['content']
                # ç®€å•è§£æ
                import json as j
                match = re.search(r'\{[^}]+\}', result)
                if match:
                    data = j.loads(match.group())
                    tweet['score'] = min(100, max(0, int(data.get('score', 50))))
                    tweet['summary'] = data.get('summary', tweet['content'][:80])
                    tweet['category'] = data.get('category', 'å…¶ä»–')
                else:
                    raise ValueError("No JSON")
            except:
                tweet['score'] = 50
                tweet['summary'] = tweet['content'][:80] + "..." if len(tweet['content']) > 80 else tweet['content']
                tweet['category'] = "å…¶ä»–"
    except Exception as e:
        print(f"âš ï¸ AIè¯„åˆ†å¤±è´¥: {e}")
        for t in tweets:
            t['score'] = 50
            t['summary'] = t['content'][:80] + "..." if len(t['content']) > 80 else t['content']
            t['category'] = "å…¶ä»–"
    
    return tweets

def main():
    # 1. åŠ è½½ç°æœ‰æ•°æ®
    data, file_path = load_existing_data()
    if not data:
        print("âŒ æ— æ³•è¯»å–ç°æœ‰æ•°æ®ï¼Œé€€å‡º")
        sys.exit(1)
    
    # 2. æŠ“å–Twitter
    tweets = fetch_tweets_simple()
    
    # 3. AIè¯„åˆ†
    tweets = ai_score(tweets)
    
    # 4. æ’åºå–Top10
    tweets = sorted(tweets, key=lambda x: x.get('score', 0), reverse=True)[:10]
    
    print(f"\nğŸ† æœ€ç»ˆé€‰æ‹© {len(tweets)} æ¡æ¨æ–‡")
    for i, t in enumerate(tweets, 1):
        print(f"  {i}. [{t.get('score',0)}åˆ†] {t['author']}: {t.get('summary', t['content'])[:40]}...")
    
    # 5. æ›´æ–°thoughtsï¼ˆæ¨ç‰¹ç›‘æ§ï¼‰- ä¿ç•™åŸæœ‰æ•°æ®
    data['thoughts'] = [{
        "content": f"[{t.get('category','å…¶ä»–')}] {t['author']}: {t.get('summary', t['content'])}",
        "time": t['time'],
        "link": t['link']
    } for t in tweets]
    
    # 6. æ›´æ–°æ—¥æœŸ
    data['date'] = datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')
    data['dateEn'] = datetime.now().strftime('%B %d, %Y')
    
    # 7. ä¿å­˜åˆ°åŸæ–‡ä»¶ä½ç½®
    print(f"\nğŸ’¾ ä¿å­˜åˆ° {file_path}...")
    os.makedirs(os.path.dirname(file_path), exist_ok=True)
    with open(file_path, 'w', encoding='utf-8') as f:
        f.write(f"const dailyContent = {json.dumps(data, indent=2, ensure_ascii=False)};")
    
    print(f"âœ… å®Œæˆï¼")
    print(f"   - æ¨ç‰¹ç›‘æ§: {len(data['thoughts'])} æ¡")
    print(f"   - RSS: {len(data.get('rss', []))} æ¡")
    print(f"   - AI: {len(data.get('ai', []))} æ¡")
    
    # 8. åˆ›å»ºæ ‡è®°æ–‡ä»¶ï¼ˆåœ¨åŒä¸€ç›®å½•ï¼‰
    flag_path = os.path.join(os.path.dirname(file_path), '..', 'content_updated.flag')
    with open(flag_path, 'w') as f:
        f.write('updated')
    
    print("\n" + "=" * 60)

if __name__ == "__main__":
    main()
